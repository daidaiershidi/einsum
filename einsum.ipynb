{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_operands(operands):\n",
    "    for i, operand in enumerate(operands):\n",
    "        print('{} shape:{}'.format(i, operand.shape))\n",
    "def einsum_label_to_index(label):\n",
    "    if (label == '.'):\n",
    "        return 52\n",
    "    NUM_OF_LETTERS = ord('z') - ord('a') + 1;\n",
    "    return (ord(label) - ord('A')) if(label.isupper()) else (NUM_OF_LETTERS + (ord(label) - ord('a')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einsum_label_to_index('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def np_unsqueeze(np_array, axis):\n",
    "    shape = np.shape(np_array)\n",
    "    if (axis > len(shape)):\n",
    "        raise(\" np_unsqueeze error! \")\n",
    "    new_shape = []\n",
    "    for i in range(len(shape)):\n",
    "        if (i != axis):\n",
    "            new_shape.append(slice(0, shape[i]))\n",
    "        else:\n",
    "            new_shape.append(np.newaxis)\n",
    "            new_shape.append(slice(0, shape[i]))\n",
    "    if (axis == len(shape)):\n",
    "        new_shape.append(np.newaxis)\n",
    "    return np_array[new_shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 1)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randn(2,3)\n",
    "np_unsqueeze(a, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_bmm(array1, array2, _lro, _lo, _ro, _sum_dim_, out_shape):\n",
    "    import torch\n",
    "#     print(_lro, _lo, _ro, _sum_dim_, out_shape)\n",
    "    #     out = np_bmm(array1, array2, [3],[0,1,2],[4],[5,6,7])\n",
    "    #     array1 # (8, \\5, 6, 7, \\2, 3, 4, \\1)  lro lo sum ro\n",
    "    #     array2 # (8, \\2, 3, 4, \\10, \\1, 1, 1) lro sum ro lo\n",
    "    ###########################################################################\n",
    "    split_dim = []\n",
    "    for _idx in (_lro+_lo+_sum_dim_+_ro):\n",
    "        if _idx in _lro:\n",
    "            split_dim.append(0)\n",
    "        if _idx in _lo:\n",
    "            split_dim.append(1)\n",
    "        if _idx in _sum_dim_:\n",
    "            split_dim.append(2)\n",
    "    \n",
    "    lshape = [1]*3\n",
    "    for i in range(len(split_dim)):\n",
    "        lshape[split_dim[i]] *= np.shape(array1)[i]\n",
    "    array1 = torch.tensor(np.reshape(array1, lshape))\n",
    "    ###########################################################################\n",
    "    split_dim = []\n",
    "    for _idx in (_lro+_sum_dim_+_ro+_lo):\n",
    "        if _idx in _lro:\n",
    "            split_dim.append(0)\n",
    "        if _idx in _sum_dim_:\n",
    "            split_dim.append(1)\n",
    "        if _idx in _ro:\n",
    "            split_dim.append(2)\n",
    "    \n",
    "    rshape = [1]*3\n",
    "    for i in range(len(split_dim)):\n",
    "        rshape[split_dim[i]] *= np.shape(array2)[i]\n",
    "    array2 = torch.tensor(np.reshape(array2, rshape))\n",
    "#     print(lshape, rshape, array1.shape, array2.shape)\n",
    "    ###########################################################################\n",
    "    out = torch.bmm(array1, array2)\n",
    "    out = out.numpy()\n",
    "    out = np.reshape(out, out_shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# result, permuted_operands[i], sum_dims, false\n",
    "def maybe_wrap_dim(dim, ndims):\n",
    "    _min = -1*ndims\n",
    "    _max = ndims - 1\n",
    "#     print(dim, _min, _max)\n",
    "    if (dim<_min or dim>_max):\n",
    "        raise(\"seen error\")\n",
    "    if (dim < 0):\n",
    "        dim += ndims\n",
    "    return dim\n",
    "def sumproduct_pair(left_, right_, sum_dims_, keep_dim_):\n",
    "#     left_ = np.random.randn(5, 6, 7, 8, 1, 2, 3, 4)\n",
    "#     right_ = np.random.randn(1, 1, 1, 8, 10, 2, 3, 4)\n",
    "#     sum_dims_ = [5,6,7]\n",
    "#     keep_dim_ = False\n",
    "#     print('*'*80)\n",
    "#     print(np.shape(left_))\n",
    "#     print(np.shape(right_))\n",
    "#     print(sum_dims_)\n",
    "\n",
    "    dim = len(left_.shape)\n",
    "\n",
    "    # dim_list_to_bitset(sum_dims_, dim)\n",
    "    seen = [-1]*(max(sum_dims_)+1)\n",
    "    for i in sum_dims_:\n",
    "        seen[i] = (maybe_wrap_dim(i, dim))\n",
    "#     print('\\n')\n",
    "#     print('sum_dims:', seen)\n",
    "    sum_dims = seen\n",
    "\n",
    "    lro = []\n",
    "    lo = []\n",
    "    ro = []\n",
    "    lro_size = 1\n",
    "    lo_size = 1\n",
    "    ro_size = 1\n",
    "    sum_size = 1\n",
    "    left = left_\n",
    "    right = right_\n",
    "\n",
    "    for i in range(dim):\n",
    "        sl = (left.shape[i] > 1)\n",
    "        sr = (right.shape[i] > 1)\n",
    "        if (sum_dims[i] != -1):\n",
    "            if (sl and sr):\n",
    "                sum_size *= left.shape[i]\n",
    "            elif (sl):\n",
    "                left = np.sum(left, i, keepdims=True)\n",
    "            elif (sr):\n",
    "                right = np.sum(right, i, keepdims=True)\n",
    "        elif (sl and sr):\n",
    "            lro.append(i)\n",
    "            lro_size *= left.shape[i]\n",
    "        elif (sl):\n",
    "            lo.append(i)\n",
    "            lo_size *= left.shape[i]\n",
    "        else:\n",
    "            ro.append(i)\n",
    "            ro_size *= right.shape[i]\n",
    "#     print('\\n')\n",
    "#     print('lro:', lro, 'lo:', lo, 'ro:', ro, 'lro_size:', lro_size, 'lo_size:', lo_size, 'ro_size:', ro_size, 'sum_size:', sum_size)\n",
    "\n",
    "    out_size = []\n",
    "    for i, _lro in enumerate(lro):\n",
    "        out_size.append(left.shape[_lro])\n",
    "    for i, _lo in enumerate(lo):\n",
    "        out_size.append(left.shape[_lo])\n",
    "    for i, _sum_dims_ in enumerate(sum_dims_):\n",
    "        out_size.append(1)\n",
    "    for i, _ro in enumerate(ro):\n",
    "        out_size.append(right.shape[_ro])\n",
    "#     print('out_size:', out_size)\n",
    "\n",
    "    lpermutation = lro.copy()\n",
    "    lpermutation += lo\n",
    "    lpermutation += sum_dims_\n",
    "    lpermutation += ro\n",
    "#     print('\\n')\n",
    "#     print('lpermutation:', lpermutation)\n",
    "\n",
    "    rpermutation = lro.copy()\n",
    "    rpermutation += sum_dims_\n",
    "    rpermutation += ro\n",
    "    rpermutation += lo\n",
    "#     print('\\n')\n",
    "#     print('rpermutation:', rpermutation)\n",
    "\n",
    "    opermutation = [-1]*(len(lro)+len(lo)+len(sum_dims_)+len(ro))\n",
    "    for i, _it in enumerate(lro+lo+sum_dims_+ro):\n",
    "        opermutation[i] = _it\n",
    "#     print('\\n')\n",
    "#     print('opermutation:', opermutation)\n",
    "\n",
    "    ###############################################################\n",
    "    out_shape = []\n",
    "    for i in range(len(lo+ro+lro)):\n",
    "        out_shape.append(max(np.shape(left)[i], np.shape(right)[i]))\n",
    "#     print('out_shape:', out_shape)\n",
    "    ###############################################################\n",
    "\n",
    "    left = np.transpose(left, tuple(lpermutation))\n",
    "    right= np.transpose(right, tuple(rpermutation))\n",
    "#     print('\\n')\n",
    "#     print(left.shape, right.shape)\n",
    "\n",
    "    _sum_dim = []\n",
    "    for i in range(len(np.shape(left))):\n",
    "        if i not in (lro+lo+ro):\n",
    "            _sum_dim.append(i)\n",
    "    bmm_out = np_bmm(left, right, lro, lo, ro, _sum_dim, out_shape)\n",
    "    return bmm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 7, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "left_ = np.random.randn(5, 6, 7, 8, 1, 2, 3, 4)\n",
    "right_ = np.random.randn(1, 1, 1, 8, 10, 2, 3, 4)\n",
    "sum_dims_ = [5,6,7]\n",
    "keep_dim_ = False\n",
    "out = sumproduct_pair(left_, right_, sum_dims_, keep_dim_)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def einsum(equation, operands):\n",
    "    op_labels = [[]]\n",
    "    lhs = equation.split('->')[0]\n",
    "    curr_op = 0\n",
    "    ELLIPSIS = 52\n",
    "    found_ell = False\n",
    "    for i, label in enumerate(lhs):\n",
    "        if (label == ' '):\n",
    "            continue\n",
    "        elif (label == '.'):\n",
    "            op_labels[curr_op].append(ELLIPSIS)\n",
    "            found_ell = True\n",
    "        elif (label == ','):\n",
    "            curr_op += 1\n",
    "            found_ell = False\n",
    "            op_labels.append([])\n",
    "        else:\n",
    "            op_labels[curr_op].append(einsum_label_to_index(label))\n",
    "    ###################################################print\n",
    "#     print(\"op_labels：\\n\", op_labels)\n",
    "#     print('\\n')\n",
    "    ###################################################print\n",
    "    \n",
    "    TOTAL_LABELS = 52\n",
    "    label_count = [0]*TOTAL_LABELS\n",
    "    ell_num_dim = 0\n",
    "    for i, operand in enumerate(operands):\n",
    "        labels = op_labels[i]\n",
    "        shape = np.shape(operand)\n",
    "        ndims = len(shape)\n",
    "        nlabels = len(labels)\n",
    "        has_ellipsis = False\n",
    "\n",
    "        for label in labels:\n",
    "            if (label == ELLIPSIS):\n",
    "                nlabels -= 1\n",
    "                has_ellipsis = True\n",
    "                ell_num_dim = max(ell_num_dim, ndims - nlabels) # 维度数量 - 除了.的字母数量 = 最大的.的数量\n",
    "            else:\n",
    "                label_count[label] += 1\n",
    "    ###################################################print\n",
    "#     print('label_count:')\n",
    "#     for i in range(TOTAL_LABELS):\n",
    "#         if (label_count[i] != 0):\n",
    "#             print(\"{}:{}  \".format(i, label_count[i]), end='')\n",
    "#     print('\\n')\n",
    "    ###################################################print\n",
    "\n",
    "    label_perm_index = [-1]*TOTAL_LABELS\n",
    "    perm_index = 0\n",
    "    ell_index = 0\n",
    "    found_ell = False\n",
    "\n",
    "    if (len(equation.split('->')) == 1):\n",
    "        perm_index = ell_num_dim\n",
    "        found_ell = True\n",
    "        for label, _label_count in enumerate(label_count):\n",
    "            if (_label_count == 1):\n",
    "                label_perm_index[label] = perm_index # 默认输入里.的维度是输出的维度，把所有字母排在后面\n",
    "                perm_index += 1\n",
    "    else:\n",
    "        rhs = equation.split('->')[1]\n",
    "        for i, label in enumerate(rhs):\n",
    "            if (label == ' '):\n",
    "                continue\n",
    "            elif (label == '.'):\n",
    "                ell_index = perm_index\n",
    "                perm_index += ell_num_dim # 如果输出也有点就在中间留出 ell_num_dim 个位置\n",
    "                found_ell = True\n",
    "            else:\n",
    "                index = einsum_label_to_index(label)\n",
    "                label_perm_index[index] = perm_index # 首先留出输出字母的位置\n",
    "                perm_index += 1\n",
    "    ###################################################print\n",
    "#     print('label_perm_index:')\n",
    "#     for i in range(TOTAL_LABELS):\n",
    "#         if (label_perm_index[i] != -1):\n",
    "#             print(\"{}:{}  \".format(i, label_perm_index[i]), end='')\n",
    "#     print('\\n')\n",
    "    ###################################################print\n",
    "    out_size = perm_index\n",
    "    if (found_ell is False):\n",
    "        ell_index = perm_index # ell_index 是存的输出字母的位置\n",
    "        perm_index += ell_num_dim # 如果输出没有点就在最后留出 ell_num_dim 个位置， ell_num_dim 不一定不是0，取决于输入\n",
    "\n",
    "    for label in range(TOTAL_LABELS):\n",
    "        if (label_count[label]>0 and label_perm_index[label] == -1):\n",
    "            label_perm_index[label] = perm_index # label_perm_index 不存在输出字母串的输入字母在最后这些位置\n",
    "            perm_index += 1\n",
    "    ###################################################print\n",
    "#     print('label_perm_index:')\n",
    "#     for i in range(TOTAL_LABELS):\n",
    "#         if (label_perm_index[i] != -1):\n",
    "#             print(\"{}:{}  \".format(i, label_perm_index[i]), end='')\n",
    "#     print('\\n')\n",
    "    ###################################################print\n",
    "\n",
    "    permuted_operands = []\n",
    "    for i, operand in enumerate(operands):\n",
    "        perm_shape = [-1]*perm_index\n",
    "        label_dim = [-1]*TOTAL_LABELS\n",
    "        labels = op_labels[i]\n",
    "        original_sizes = np.shape(operand)\n",
    "\n",
    "        j = 0\n",
    "        for label in labels:\n",
    "            operand = operands[i]\n",
    "            if (label == ELLIPSIS):\n",
    "                num_missing_dim = ell_num_dim - (len(original_sizes) - len(labels) + 1)\n",
    "                for k in range(num_missing_dim):\n",
    "                    operands[i] = np_unsqueeze(operand, j) # 这个能补充到 perm_index 的维度, perm_index 是输出字母 + 一个或多个输入最大.数 + 输入字母\n",
    "                for k in range(ell_num_dim):\n",
    "                    perm_shape[ell_index + k] = j # perm_shape （代表每一个输入）里是先排 输入.的位置\n",
    "                    j += 1\n",
    "            elif (label_dim[label] != -1):\n",
    "                dim = label_dim[label]\n",
    "                operand = np.diagonal(operand, offset=0, axis1=dim, axis2=j)\n",
    "                operands[i] = np.moveaxis(operand, -1, dim)\n",
    "            else:\n",
    "                label_dim[label] = j\n",
    "                perm_shape[label_perm_index[label]] = j\n",
    "                j += 1\n",
    "        # [0,1,2,3,4,5,6,7] -> [3,4,-1,-1,0,1,2,-1]\n",
    "        ###################################################print\n",
    "#         print('perm_shape:', perm_shape)\n",
    "        ###################################################print\n",
    "        for perm_shape_i, index in enumerate(perm_shape):\n",
    "            operand = operands[i]\n",
    "            if (index == -1):\n",
    "                operands[i] = np_unsqueeze(operand, len(np.shape(operand)))\n",
    "                perm_shape[perm_shape_i] = j\n",
    "                j += 1\n",
    "        # [3,4,-1,-1,0,1,2,-1] -> [3,4,5,6,0,1,2,7]\n",
    "        ###################################################print\n",
    "#         print('perm_shape:', perm_shape)\n",
    "        ###################################################print\n",
    "        operand = operands[i]\n",
    "        operand = np.transpose(operand, tuple(perm_shape))\n",
    "        permuted_operands.append(operand)\n",
    "    ###################################################print\n",
    "#     print_operands(permuted_operands)\n",
    "    ###################################################print\n",
    "\n",
    "    dim_last_op = [0]*perm_index\n",
    "    has_zero_size_dim = False\n",
    "    for dim in range(perm_index):\n",
    "        broadcast_size = permuted_operands[0].shape[dim]\n",
    "        for i in range(1, len(operands)):\n",
    "            dim_size = permuted_operands[i].shape[dim]\n",
    "            if (broadcast_size!= dim_size and broadcast_size!=1 and dim_size!=1):\n",
    "                raise(\"near dim_last_op\")\n",
    "            if (dim_size != 1):\n",
    "                broadcast_size = dim_size\n",
    "                dim_last_op[dim] = i\n",
    "        has_zero_size_dim = has_zero_size_dim or (broadcast_size == 0)\n",
    "    ###################################################print\n",
    "#     print('\\n')\n",
    "#     print('dim_last_op:', dim_last_op)\n",
    "#     print('has_zero_size_dim:', has_zero_size_dim)\n",
    "    ###################################################print\n",
    "        \n",
    "        \n",
    "    result = permuted_operands[0]\n",
    "    # has_zero_size_dim = True\n",
    "    if (has_zero_size_dim):\n",
    "        out_shape = [-1]*out_size\n",
    "        for i in range(out_size):\n",
    "            out_shape[i] = permuted_operands[dim_last_op[i]].shape[i]\n",
    "        return np.zeros(out_shape)\n",
    "\n",
    "    dim = out_size\n",
    "    for i in range(dim, perm_index):\n",
    "        if (dim_last_op[i] == 0):\n",
    "            if (result.shape[dim] == 1):\n",
    "                result = np.squeeze(result, dim)\n",
    "                dim -= 1\n",
    "            else:\n",
    "                result = np.sum(result, dim)\n",
    "                dim -= 1\n",
    "        dim += 1\n",
    "        \n",
    "    for i in range(1, len(permuted_operands)):\n",
    "        sum_dims = []\n",
    "        dim = out_size\n",
    "        for j in range(dim, perm_index):\n",
    "            if (dim_last_op[j] < i):\n",
    "                permuted_operands[i] = np.squeeze(permuted_operands[i], dim)\n",
    "                dim -= 1\n",
    "            elif (dim_last_op[j] == i):\n",
    "                if (result.shape[dim] == 1):\n",
    "                    permuted_operands[i] = np.sum(permuted_operands[i], dim)\n",
    "                    result = np.squeeze(result, dim)\n",
    "                    dim -= 1\n",
    "                else:\n",
    "                    sum_dims.append(dim)\n",
    "            dim += 1\n",
    "#         print('sum_dims:',sum_dims)\n",
    "#         print('compute:', np.shape(result), np.shape(permuted_operands[i]))\n",
    "        if (len(sum_dims) == 0):\n",
    "#             print('直接算')\n",
    "            result = np.multiply(result, permuted_operands[i])\n",
    "        elif (len(sum_dims) == len(result.shape)):\n",
    "#             print('flatten')\n",
    "            result = result.flatten().dot(permuted_operands[i].flatten())\n",
    "        else:\n",
    "#             print('sumproduct_pair')\n",
    "            result = sumproduct_pair(result, permuted_operands[i], sum_dims, False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 7, 8, 10, 9) tensor(1.1369e-12, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "operands = []\n",
    "a1 = np.random.randn(1,2,3,4,5,6)\n",
    "a2 = np.random.randn(1,2,3,4,7,8,9)\n",
    "a3 = np.random.randn(1,2,3,4,8,10)\n",
    "operands.append(a1)\n",
    "operands.append(a2)\n",
    "operands.append(a3)\n",
    "equation = \"abcdef,abcdghi,abcdhk->efghki\" # 5,6,7,8,10\n",
    "out = einsum(equation, operands)\n",
    "np_out = torch.einsum(equation, torch.tensor(a1), torch.tensor(a2), torch.tensor(a3))\n",
    "print(out.shape, (np_out-out).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7, 8) tensor(6.4393e-14, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "operands = []\n",
    "a1 = np.random.randn(1,2,3,4,5,6)\n",
    "a2 = np.random.randn(1,2,3,4,7,8,9)\n",
    "operands.append(a1)\n",
    "operands.append(a2)\n",
    "equation = \"abcdef,abcdghi->egh\" # 5,6,7,8,10\n",
    "out = einsum(equation, operands)\n",
    "np_out = torch.einsum(equation, torch.tensor(a1), torch.tensor(a2))\n",
    "print(out.shape, (np_out-out).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "'.' must only occur in ellipsis, operand 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-307-41ab75ed4615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mequation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"a.ef,a.ghi->efgh\"\u001b[0m \u001b[1;31m# 5,6,7,8,10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mnp_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp_out\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Software\\Anaconda\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36meinsum\u001b[1;34m(equation, *operands)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: '.' must only occur in ellipsis, operand 0"
     ]
    }
   ],
   "source": [
    "operands = []\n",
    "a1 = np.random.randn(1,2,3,4,5,6)\n",
    "a2 = np.random.randn(1,2,3,4,7,8,9)\n",
    "operands.append(a1)\n",
    "operands.append(a2)\n",
    "equation = \"a.ef,a.ghi->efgh\" # 5,6,7,8,10\n",
    "out = einsum(equation, operands)\n",
    "np_out = torch.einsum(equation, torch.tensor(a1), torch.tensor(a2))\n",
    "print(out.shape, (np_out-out).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 8)\n"
     ]
    }
   ],
   "source": [
    "operands = []\n",
    "operands.append(np.random.randn(1,2,3,4,5,6))\n",
    "operands.append(np.random.randn(1,2,3,4,7,8,9))\n",
    "equation = \"abcdef,abcdghi->.gh\" # 5,6,7,8,10\n",
    "out = einsum(equation, operands)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7, 8, 10)\n"
     ]
    }
   ],
   "source": [
    "operands = []\n",
    "operands.append(np.random.randn(1,2,3,4,5,6))\n",
    "operands.append(np.random.randn(1,2,3,4,7,8,9))\n",
    "operands.append(np.random.randn(1,2,3,4,8,10))\n",
    "equation = \"a.def,a.dghi,a.dhk->eghk\" # 5,6,7,8,10\n",
    "out = einsum(equation, operands)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
